from code_generators.common.helper_functions import num_arr_to_cppArrStr
from code_generators.common.helper_functions import binary_arr_to_cppArrStr

def gen_genTF_function():
    line = ""

    line += "/* Generate twiddle factors for radix 2 NTT. " + "\n"
    line += "In normal radix-2 case, twiddle factors are used in increasing power order" + "\n"
    line += "*/" + "\n"
    line += "void generateTFForRadix2NTT(WORD root, WORD size, WORD mod, std::vector<WORD>& TFArr){" + "\n"
    line += "  WORD tempTF = 1;" + "\n"
    line += "  for(int i=0; i<(size/2); i++){" + "\n"
    line += "    TFArr[i] = tempTF;" + "\n"
    line += "    tempTF = (WORD)((((DWORD)tempTF) * ((DWORD)root)) % ((DWORD)mod));" + "\n"
    line += "  }" + "\n"
    line += "}" + "\n"
    line += "" + "\n"

    line += "/* Generate TFs for num_of_limbs when poly size is 'size' */" + "\n"
    line += "void generateTFsForMultipleLimbs(VAR_TYPE_32 num_of_limbs, VAR_TYPE_32 size, std::vector<WORD>& workingModulus_arr, std::vector<WORD>& root_arr, std::vector<WORD> (&tfArr)[PARA_LIMBS]){" + "\n"
    line += "  for(VAR_TYPE_32 paraLimbCounter=0; paraLimbCounter<num_of_limbs; paraLimbCounter++){" + "\n"
    line += "    WORD root = root_arr[paraLimbCounter];" + "\n"
    line += "    WORD workingModulus = workingModulus_arr[paraLimbCounter];" + "\n"
    line += "    " + "\n"
    line += "    tfArr[paraLimbCounter].resize(size/2);" + "\n"
    line += "" + "\n"
    line += "    generateTFForRadix2NTT(root, size, workingModulus, tfArr[paraLimbCounter]);" + "\n"
    line += "  }" + "\n"
    line += "}" + "\n"

    return line

# This function is to convert multiple parallel limbs into different DRAM ports.
# This function does not depend on FWD or INV
def gen_reorganize_para_limbs_to_ports_tf():

    line = ""

    line += "void reorganize_para_limbs_to_ports_tf(std::vector<TF_WIDE_DATA_PER_PARA_LIMB, tapa::aligned_allocator<TF_WIDE_DATA_PER_PARA_LIMB>> (&inVec)[PARA_LIMBS][TF_PORTS_PER_PARA_LIMB], std::vector<TF_WIDE_DATA, tapa::aligned_allocator<TF_WIDE_DATA>> (&outVec)[TF_PORTS]){" + "\n"
    line += "" + "\n"
    line += "  for(int port_counter=0; port_counter<TF_PORTS; port_counter++){" + "\n"
    line += "    //init" + "\n"
    line += "    int target_per_limb_port_start = port_counter*PARA_LIMB_PORTS_PER_TF_PORT;" + "\n"
    line += "    int target_limb_idx = target_per_limb_port_start/TF_PORTS_PER_PARA_LIMB;" + "\n"
    line += "    int target_limb_port_idx = target_per_limb_port_start%TF_PORTS_PER_PARA_LIMB;" + "\n"
    line += "" + "\n"
    line += "    int num_of_data = inVec[target_limb_idx][target_limb_port_idx].size();" + "\n"
    line += "    outVec[port_counter].resize(num_of_data);" + "\n"
    line += "" + "\n"
    line += "    //assign" + "\n"
    line += "    for(int data_counter=0; data_counter<num_of_data; data_counter++){" + "\n"
    line += "      TF_WIDE_DATA val = 0;" + "\n"
    line += "      for(int per_limb_port_counter=PARA_LIMB_PORTS_PER_TF_PORT-1; per_limb_port_counter>=0; per_limb_port_counter--){" + "\n"
    line += "        int total_per_limb_ports = port_counter*PARA_LIMB_PORTS_PER_TF_PORT + per_limb_port_counter;" + "\n"
    line += "        int limb_idx = total_per_limb_ports/TF_PORTS_PER_PARA_LIMB;" + "\n"
    line += "        int limb_port_idx = total_per_limb_ports%TF_PORTS_PER_PARA_LIMB;" + "\n"
    line += "" + "\n"
    line += "        TF_WIDE_DATA_PER_PARA_LIMB limbVal;" + "\n"
    line += "        if(limb_idx<PARA_LIMBS){ " + "\n"
    line += "          limbVal = inVec[limb_idx][limb_port_idx][data_counter];" + "\n"
    line += "        }" + "\n"
    line += "        else{//In case, PARA_LIMBS is not perfectly divisible by PARA_LIMB_PORTS_PER_TF_PORT" + "\n"
    line += "          limbVal = 0;" + "\n"
    line += "        }" + "\n"
    line += "        val = val << TF_DRAM_PORT_WIDTH_PER_PARA_LIMB;" + "\n"
    line += "        val |= (TF_WIDE_DATA)limbVal;" + "\n"
    line += "      }" + "\n"
    line += "      outVec[port_counter][data_counter] = val;" + "\n"
    line += "    }" + "\n"
    line += "  }" + "\n"
    line += "}" + "\n"

    return line

def gen_fwd_TF_data_rearrange(designParamsVar):
    TFBuffersParamsVar = designParamsVar.TFBuffersParamsVar

    layers_per_seg = num_arr_to_cppArrStr(TFBuffersParamsVar.layers_per_seg)
    load_direction_per_seg = binary_arr_to_cppArrStr(TFBuffersParamsVar.load_direction_per_seg)

    line = ""

    line += "void fwd_organizeTFData(std::vector<WORD>& inVec, std::vector<TF_WIDE_DATA_PER_PARA_LIMB, tapa::aligned_allocator<TF_WIDE_DATA_PER_PARA_LIMB>> (&outVec)[TF_PORTS_PER_PARA_LIMB]){" + "\n"
    line += "  //number of TF tasks = vertical BUs/2" + "\n"
    line += "  std::vector<WORD> layerWiseTFBuf[H_BUG_SIZE][V_BUG_SIZE/2 * BUG_CONCAT_FACTOR];" + "\n"
    line += "" + "\n"
    line += "  std::vector<int> layerWiseTFBufDepth(H_BUG_SIZE);" + "\n"
    line += "  for(int layer=0; layer<H_BUG_SIZE; layer++){" + "\n"
    line += "    layerWiseTFBufDepth[layer] = 0;" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  //select TFs going into each TFBuf in each layer" + "\n"
    line += "  for(int stage=0; stage<logN; stage++){" + "\n"
    line += "" + "\n"
    line += "    //total TFs" + "\n"
    line += "    int num_tfs_in_this_stage = 1 << stage;" + "\n"
    line += "    int tf_stride_in_this_stage = (N/2)/num_tfs_in_this_stage; //distance between two TF values" + "\n"
    line += "" + "\n"
    line += "    //check partial BUG" + "\n"
    line += "    int dataFlowIter = stage/H_BUG_SIZE;" + "\n"
    line += "    int numberOfSupportedStages = ( logN-(dataFlowIter*H_BUG_SIZE) > H_BUG_SIZE ) ? (H_BUG_SIZE) : ( logN-(dataFlowIter*H_BUG_SIZE) );" + "\n"
    line += "    int tf_grp_size_BUG = 1 << (numberOfSupportedStages-1); //to support remaining layers, how many poly. values are grouped together is (1 << (num_partial_layers)). Since 2 poly val. need 1 TF, this is the eqn for TFs" + "\n"
    line += "    int num_tf_grps_per_BUG = V_BUG_SIZE/tf_grp_size_BUG;" + "\n"
    line += "" + "\n"
    line += "    //layer specific dist" + "\n"
    line += "    int layer_id = stage % H_BUG_SIZE;" + "\n"
    line += "    int per_BUG_diff_num_data = (1 << layer_id); //how many unique TF values are passed from this layer" + "\n"
    line += "    int per_BUG_diff_data_dist = ( (N/2)/per_BUG_diff_num_data );" + "\n"
    line += "" + "\n"
    line += "    //per buffer if two unique values are going or not" + "\n"
    line += "    //only first layer share values among 2 consec BUs. All the remaining layers always have two different values accessed by the consecutive BUs" + "\n"
    line += "    //That does not happen only when partial grp size is 1. i.e., every BU is a partial BU." + "\n"
    line += "    int num_val_accessed_by_consec_BUs;" + "\n"
    line += "    if( ( layer_id == 0 ) && ( tf_grp_size_BUG !=1 ) ){ " + "\n"
    line += "      num_val_accessed_by_consec_BUs = 1;" + "\n"
    line += "    }" + "\n"
    line += "    else{" + "\n"
    line += "      num_val_accessed_by_consec_BUs = 2;" + "\n"
    line += "    }" + "\n"
    line += "" + "\n"
    line += "    //As # BUGs increases, TFs can be spread accross different buffers. this determines that" + "\n"
    line += "    //if total number of TFs only fit into one BUG, duplicates among BUGs. " + "\n"
    line += "    //Else, if number of TFs are larger than a single BUG, hence spread accross BUGs" + "\n"
    line += "    //In that case, if number of TFs are less than total number of BUGs, that means, TFs are only spread accross (num of TFs amount/per BUG) of BUGs" + "\n"
    line += "    //If number of TFs are more than total number of BUGs, that means, TFs are spread accross BUG_CONCAT_FACTOR" + "\n"
    line += "    int BUG_concat_dist_factor = ( num_tfs_in_this_stage <= V_BUG_SIZE ) ? ( 1 ) : ( ( (num_tfs_in_this_stage/per_BUG_diff_num_data) <= BUG_CONCAT_FACTOR ) ? ( num_tfs_in_this_stage/per_BUG_diff_num_data ) : ( BUG_CONCAT_FACTOR ) ); " + "\n"
    line += "" + "\n"
    line += "    //number of unique tf values going per single iteration" + "\n"
    line += "    int unique_tf_per_iter = per_BUG_diff_num_data * num_tf_grps_per_BUG * BUG_concat_dist_factor;" + "\n"
    line += "" + "\n"
    line += "    //Number of total TFs going into a buffer" + "\n"
    line += "    //Eqn is: per \"num_val_accessed_by_consec_BUs\" depth \"unique_tf_per_iter\" values were stored. Then how much depth for \"num_tfs_in_this_stage\"" + "\n"
    line += "    int num_tfs_per_buf = num_tfs_in_this_stage / ( unique_tf_per_iter/num_val_accessed_by_consec_BUs );" + "\n"
    line += "    layerWiseTFBufDepth[layer_id] += num_tfs_per_buf;" + "\n"
    line += "" + "\n"
    line += "    int partial_dist_factor = num_tf_grps_per_BUG;" + "\n"
    line += "" + "\n"
    line += "    for(int BUG_id=0; BUG_id<BUG_CONCAT_FACTOR; BUG_id++){" + "\n"
    line += "      for(int buf_id=0; buf_id<V_BUG_SIZE/2; buf_id++){" + "\n"
    line += "        " + "\n"
    line += "        //intra partial BUG handling" + "\n"
    line += "        int tf_grp_idx = (int)( ( buf_id * 1.0 ) / ( ( 1.0 * tf_grp_size_BUG ) / 2 ) );" + "\n"
    line += "        int intra_buf_idx = (int)( buf_id % ( (tf_grp_size_BUG+1) / 2 ) ); //ceil division" + "\n"
    line += "" + "\n"
    line += "        //start index of each buffer" + "\n"
    line += "        int start_idx = ( ( ( tf_grp_idx * BUG_CONCAT_FACTOR ) + (BUG_id % BUG_concat_dist_factor ) ) * tf_stride_in_this_stage ) + \\" + "\n"
    line += "                        ( intra_buf_idx * per_BUG_diff_data_dist * 2 ) % (N/2);" + "\n"
    line += "" + "\n"
    line += "        " + "\n"
    line += "        for(int tf_count=0; tf_count<num_tfs_per_buf; tf_count++){" + "\n"
    line += "          int tf_idx;" + "\n"
    line += "          //In the case of partial group only supporting the first layer, it has to store the consec BU TF values far apart to match with the" + "\n"
    line += "          //other TFBuf modules(supporting other layers). Also the stride is not consistant in this case." + "\n"
    line += "          //It is like: 0, 2, 32, 34, 64, 66, 96, 98,... So we store 0, 32, 64, 96, ..., 2, 34, 66, 98, ..." + "\n"
    line += "          if( num_tf_grps_per_BUG > (V_BUG_SIZE/2) ){ //Hmmm...think if you can make this bit generic" + "\n"
    line += "            tf_idx = start_idx + (tf_stride_in_this_stage*BUG_concat_dist_factor)*(tf_count/((num_tfs_per_buf)/2)) + (tf_count % ((num_tfs_per_buf)/2)) * tf_stride_in_this_stage * BUG_concat_dist_factor * partial_dist_factor;" + "\n"
    line += "          }" + "\n"
    line += "          else{" + "\n"
    line += "            tf_idx = start_idx + tf_count*tf_stride_in_this_stage*BUG_concat_dist_factor*partial_dist_factor;" + "\n"
    line += "          }" + "\n"
    line += "          " + "\n"
    line += "          int write_buf = BUG_id*(V_BUG_SIZE/2) + buf_id;" + "\n"
    line += "          WORD tfVal = inVec[tf_idx];" + "\n"
    line += "          layerWiseTFBuf[layer_id][write_buf].push_back(tfVal);" + "\n"
    line += "        }" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  //make each depth even as two values going to be packed together" + "\n"
    line += "  for(int layer=0; layer<H_BUG_SIZE; layer++){" + "\n"
    line += "    if( layerWiseTFBufDepth[layer]%2==1 ){//odd" + "\n"
    line += "      layerWiseTFBufDepth[layer]+=1;" + "\n"
    line += "      for(int buf_id=0; buf_id<V_BUG_SIZE/2 * BUG_CONCAT_FACTOR; buf_id++){" + "\n"
    line += "        layerWiseTFBuf[layer][buf_id].push_back(0);" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "  }" + "\n"
    line += "  " + "\n"
    line += "  printf(\"Layerwise TF depths:\\n\");" + "\n"
    line += "  for(int layer=0; layer<H_BUG_SIZE; layer++){" + "\n"
    line += "    printf(\"layer=%d, depth=%d\\n\", layer, layerWiseTFBufDepth[layer]);" + "\n"
    line += "  }" + "\n"
    line += "  printf(\"\\n\");" + "\n"
    line += "" + "\n"
    line += "  //coelesce data" + "\n"
    line += "  if( (V_BUG_SIZE/2)*BUG_CONCAT_FACTOR > TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT*TF_PORTS_PER_PARA_LIMB ){" + "\n"
    line += "    printf(\"[ERROR][fwd_organizeTFData]:: Not enoght TF ports! Total vertical buffers=%d, Combine factor=%d\\n\", (int)(V_BUG_SIZE/2)*BUG_CONCAT_FACTOR, (int)TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT*TF_PORTS_PER_PARA_LIMB );" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  int cummulative_sum_of_assigned_layers = 0;" + "\n"
    line += "  " + "\n"
    line += "  //When there is a horizontal split(s) between BUG for TF loading, a balance (in terms of #TFs) between segments is required." + "\n"
    line += "  int layers_per_seg[TF_LOAD_H_SEGS_PER_PARA_LIMB] = " + layers_per_seg + ";" + "\n"
    line += "  bool load_direction_per_seg[TF_LOAD_H_SEGS_PER_PARA_LIMB] = " + load_direction_per_seg + ";" + "\n"
    line += "" + "\n"
    line += "  for(int h_seg_id=0; h_seg_id<TF_LOAD_H_SEGS_PER_PARA_LIMB; h_seg_id++){" + "\n"
    line += "    int num_layers = layers_per_seg[h_seg_id]; //remaining layers/remaining segments" + "\n"
    line += "    printf(\"Layers in seg id %d:\\n\", h_seg_id);" + "\n"
    line += "" + "\n"
    line += "    if(load_direction_per_seg[h_seg_id]){" + "\n"
    line += "      for(int layer_id=cummulative_sum_of_assigned_layers; layer_id<(cummulative_sum_of_assigned_layers+num_layers); layer_id++){" + "\n"
    line += "        printf(\"\\t%d\\n\", layer_id);" + "\n"
    line += "        for(int tf_count=0; tf_count<layerWiseTFBufDepth[layer_id]/2; tf_count++){ //two values packed together" + "\n"
    line += "          for(int v_seg_id=0; v_seg_id<TF_LOAD_V_SEGS_PER_PARA_LIMB; v_seg_id++){" + "\n"
    line += "            " + "\n"
    line += "            int tf_port_id = h_seg_id * TF_LOAD_V_SEGS_PER_PARA_LIMB + v_seg_id;" + "\n"
    line += "" + "\n"
    line += "            TF_WIDE_DATA_PER_PARA_LIMB val = 0;" + "\n"
    line += "" + "\n"
    line += "            for(int comb_id=TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2-1; comb_id>=0; comb_id--){" + "\n"
    line += "              val = val << (DRAM_WORD_SIZE*2);" + "\n"
    line += "              int buf_id = v_seg_id*(TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2)+comb_id;" + "\n"
    line += "              WORD smallVal_0 = layerWiseTFBuf[layer_id][buf_id][2*tf_count];" + "\n"
    line += "              WORD smallVal_1 = layerWiseTFBuf[layer_id][buf_id][2*tf_count+1];" + "\n"
    line += "              val = val | ( ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_1 ) << WORD_SIZE ) | ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_0 );" + "\n"
    line += "            }" + "\n"
    line += "            outVec[tf_port_id].push_back(val);" + "\n"
    line += "          }" + "\n"
    line += "        }" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "    else{" + "\n"
    line += "      for(int layer_id=(cummulative_sum_of_assigned_layers+num_layers-1); layer_id>=(cummulative_sum_of_assigned_layers); layer_id--){" + "\n"
    line += "        printf(\"\\t%d\\n\", layer_id);" + "\n"
    line += "        for(int tf_count=0; tf_count<layerWiseTFBufDepth[layer_id]/2; tf_count++){ //two values packed together" + "\n"
    line += "          for(int v_seg_id=0; v_seg_id<TF_LOAD_V_SEGS_PER_PARA_LIMB; v_seg_id++){" + "\n"
    line += "            " + "\n"
    line += "            int tf_port_id = h_seg_id * TF_LOAD_V_SEGS_PER_PARA_LIMB + v_seg_id;" + "\n"
    line += "" + "\n"
    line += "            TF_WIDE_DATA_PER_PARA_LIMB val = 0;" + "\n"
    line += "" + "\n"
    line += "            for(int comb_id=TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2-1; comb_id>=0; comb_id--){" + "\n"
    line += "              val = val << (DRAM_WORD_SIZE*2);" + "\n"
    line += "              int buf_id = v_seg_id*(TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2)+comb_id;" + "\n"
    line += "              WORD smallVal_0 = layerWiseTFBuf[layer_id][buf_id][2*tf_count];" + "\n"
    line += "              WORD smallVal_1 = layerWiseTFBuf[layer_id][buf_id][2*tf_count+1];" + "\n"
    line += "              val = val | ( ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_1 ) << WORD_SIZE ) | ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_0 );" + "\n"
    line += "            }" + "\n"
    line += "            outVec[tf_port_id].push_back(val);" + "\n"
    line += "          }" + "\n"
    line += "        }" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "    cummulative_sum_of_assigned_layers+=num_layers;" + "\n"
    line += "  }" + "\n"
    line += "}" + "\n"
    
    return line

def gen_inv_TF_data_rearrange(designParamsVar):
    TFBuffersParamsVar = designParamsVar.TFBuffersParamsVar

    layers_per_seg = num_arr_to_cppArrStr(TFBuffersParamsVar.layers_per_seg)
    load_direction_per_seg = binary_arr_to_cppArrStr(TFBuffersParamsVar.load_direction_per_seg)

    line = ""

    line += "void inv_organizeTFData(std::vector<WORD>& inVec, std::vector<TF_WIDE_DATA_PER_PARA_LIMB, tapa::aligned_allocator<TF_WIDE_DATA_PER_PARA_LIMB>> (&outVec)[TF_PORTS_PER_PARA_LIMB]){" + "\n"
    line += "  //number of TF tasks = vertical BUs/2" + "\n"
    line += "  std::vector<WORD> layerWiseTFBuf[H_BUG_SIZE][V_BUG_SIZE/2 * BUG_CONCAT_FACTOR];" + "\n"
    line += "" + "\n"
    line += "  std::vector<int> layerWiseTFBufDepth(H_BUG_SIZE);" + "\n"
    line += "  for(int layer=0; layer<H_BUG_SIZE; layer++){" + "\n"
    line += "    layerWiseTFBufDepth[layer] = 0;" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  //select TFs going into each TFBuf in each layer" + "\n"
    line += "  for(int stage=0; stage<logN; stage++){" + "\n"
    line += "    " + "\n"
    line += "    //total TFs" + "\n"
    line += "    int num_tfs_in_this_stage = 1 << stage;" + "\n"
    line += "    int tf_change_freq = (N/2)/num_tfs_in_this_stage; //distance between two TF values" + "\n"
    line += "" + "\n"
    line += "    //check partial BUG" + "\n"
    line += "    int dataFlowIter = (logN - 1 - stage)/H_BUG_SIZE;" + "\n"
    line += "    int numberOfSupportedStages = ( logN-(dataFlowIter*H_BUG_SIZE) > H_BUG_SIZE ) ? (H_BUG_SIZE) : ( logN-(dataFlowIter*H_BUG_SIZE) );" + "\n"
    line += "    int tf_grp_size_BUG = 1 << (numberOfSupportedStages-1); //to support remaining layers, how many poly. values are grouped together is (1 << (num_partial_layers)). Since 2 poly val. need 1 TF, this is the eqn for TFs" + "\n"
    line += "    int num_tf_grps_per_BUG = V_BUG_SIZE/tf_grp_size_BUG;" + "\n"
    line += "" + "\n"
    line += "    //layer specific dist" + "\n"
    line += "    int layer_id = (logN - stage - 1) % H_BUG_SIZE;" + "\n"
    line += "    int per_BUG_diff_num_data = ( 1 << ( (H_BUG_SIZE - 1) - layer_id ) ); //how many unique TF values are passed from this layer" + "\n"
    line += "    // int per_BUG_idx_change_freq = ( (V_BUG_SIZE)/per_BUG_diff_num_data );" + "\n"
    line += "    int BUG_buf_val_change_freq = (( (V_BUG_SIZE)/per_BUG_diff_num_data ) + 1)/2;" + "\n"
    line += "" + "\n"
    line += "    //per buffer if two unique values are going or not" + "\n"
    line += "    //only first layer need 2 value access for 2 consec BUs. All the remaining layers always share the same value by the consecutive BUs" + "\n"
    line += "    //That does not happen only when partial grp size is 1. i.e., every BU is a partial BU. In that case, it has to be 1st stage of NTT and that has only one value." + "\n"
    line += "    int num_val_accessed_by_consec_BUs;" + "\n"
    line += "    if( ( layer_id == 0 ) && ( tf_grp_size_BUG !=1 ) ){" + "\n"
    line += "      num_val_accessed_by_consec_BUs = 2;" + "\n"
    line += "    }" + "\n"
    line += "    else{" + "\n"
    line += "      num_val_accessed_by_consec_BUs = 1;" + "\n"
    line += "    }" + "\n"
    line += "" + "\n"
    line += "    //As # BUGs increases, TFs can be spread accross different buffers. this determines that" + "\n"
    line += "    //if TF change frequency is more than one BUG, that means same TF(s) is being used accross multiple BUG. i.e., duplicating" + "\n"
    line += "    //Else, if TF change freq is smaller than a single BUG, that means different TFs are send in different BUGs" + "\n"
    line += "    int BUG_concat_dist_factor = ( tf_change_freq > V_BUG_SIZE ) ? ( ( ( (BUG_CONCAT_FACTOR*V_BUG_SIZE)/(tf_change_freq*per_BUG_diff_num_data) ) > 0 ) ? ( (BUG_CONCAT_FACTOR*V_BUG_SIZE)/(tf_change_freq*per_BUG_diff_num_data) ) : (1) ) : ( BUG_CONCAT_FACTOR );" + "\n"
    line += "" + "\n"
    line += "    //number of unique tf values going per single iteration" + "\n"
    line += "    int unique_tf_per_iter = (per_BUG_diff_num_data/num_tf_grps_per_BUG) * BUG_concat_dist_factor;" + "\n"
    line += "" + "\n"
    line += "    //Number of total TFs going into a buffer" + "\n"
    line += "    //Eqn is: per \"num_val_accessed_by_consec_BUs\" depth \"unique_tf_per_iter\" values were stored. Then how much depth for \"num_tfs_in_this_stage\"" + "\n"
    line += "    int num_tfs_per_buf = num_tfs_in_this_stage / ( unique_tf_per_iter/num_val_accessed_by_consec_BUs );" + "\n"
    line += "    layerWiseTFBufDepth[layer_id] += num_tfs_per_buf;" + "\n"
    line += "    " + "\n"
    line += "    //Because of partial groups, multiple TF groups can be stored in the same BUG. this variable determines that" + "\n"
    line += "    int partial_dist_factor = num_tf_grps_per_BUG;" + "\n"
    line += "" + "\n"
    line += "    for(int BUG_id=0; BUG_id<BUG_CONCAT_FACTOR; BUG_id++){" + "\n"
    line += "      for(int buf_id=0; buf_id<V_BUG_SIZE/2; buf_id++){" + "\n"
    line += "        " + "\n"
    line += "        //start index of each buffer" + "\n"
    line += "        int start_idx = ( ( BUG_id / (BUG_CONCAT_FACTOR/BUG_concat_dist_factor) ) * per_BUG_diff_num_data * partial_dist_factor ) + \\" + "\n"
    line += "                        ( ( (buf_id % ((tf_grp_size_BUG+1)/2)) / BUG_buf_val_change_freq ) * num_val_accessed_by_consec_BUs );" + "\n"
    line += "" + "\n"
    line += "        for(int tf_count=0; tf_count<num_tfs_per_buf; tf_count++){" + "\n"
    line += "" + "\n"
    line += "          int tf_idx = start_idx + (tf_count/num_val_accessed_by_consec_BUs) * per_BUG_diff_num_data * BUG_concat_dist_factor + (tf_count % num_val_accessed_by_consec_BUs);" + "\n"
    line += "          int write_buf = BUG_id*(V_BUG_SIZE/2) + buf_id;" + "\n"
    line += "          WORD tfVal = inVec[tf_idx];" + "\n"
    line += "          layerWiseTFBuf[layer_id][write_buf].push_back(tfVal);" + "\n"
    line += "        }" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  //make each depth even as two values going to be packed together" + "\n"
    line += "  for(int layer=0; layer<H_BUG_SIZE; layer++){" + "\n"
    line += "    if( layerWiseTFBufDepth[layer]%2==1 ){ //odd" + "\n"
    line += "      layerWiseTFBufDepth[layer]+=1;" + "\n"
    line += "      for(int buf_id=0; buf_id<V_BUG_SIZE/2 * BUG_CONCAT_FACTOR; buf_id++){" + "\n"
    line += "        layerWiseTFBuf[layer][buf_id].push_back(0);" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "  }" + "\n"
    line += "  " + "\n"
    line += "  printf(\"Layerwise TF depths:\\n\");" + "\n"
    line += "  for(int layer=0; layer<H_BUG_SIZE; layer++){" + "\n"
    line += "    printf(\"layer=%d, depth=%d\\n\", layer, layerWiseTFBufDepth[layer]);" + "\n"
    line += "  }" + "\n"
    line += "  printf(\"\\n\");" + "\n"
    line += "" + "\n"
    line += "  //coelesce data" + "\n"
    line += "  if( (V_BUG_SIZE/2)*BUG_CONCAT_FACTOR > TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT*TF_PORTS_PER_PARA_LIMB ){ // a self check" + "\n"
    line += "    printf(\"[ERROR][inv_organizeTFData]:: Not enoght TF ports! Total vertical buffers=%d, Combine factor=%d\\n\", (int)(V_BUG_SIZE/2)*BUG_CONCAT_FACTOR, (int)TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT*TF_PORTS_PER_PARA_LIMB );" + "\n"
    line += "    exit(1);" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  int cummulative_sum_of_assigned_layers = 0;" + "\n"
    line += "" + "\n"
    line += "  //When there is a horizontal split(s) between BUG for TF loading, a balance (in terms of #TFs) between segments is required." + "\n"
    line += "  int layers_per_seg[TF_LOAD_H_SEGS_PER_PARA_LIMB] = " + layers_per_seg + ";" + "\n"
    line += "  bool load_direction_per_seg[TF_LOAD_H_SEGS_PER_PARA_LIMB] = " + load_direction_per_seg + ";" + "\n"
    line += "" + "\n"
    line += "  for(int h_seg_id=0; h_seg_id<TF_LOAD_H_SEGS_PER_PARA_LIMB; h_seg_id++){" + "\n"
    line += "    int num_layers = layers_per_seg[h_seg_id]; //remaining layers/remaining segments" + "\n"
    line += "    printf(\"Layers in seg id %d:\\n\", h_seg_id);" + "\n"
    line += "" + "\n"
    line += "    if(load_direction_per_seg[h_seg_id]){" + "\n"
    line += "      for(int layer_id=cummulative_sum_of_assigned_layers; layer_id<(cummulative_sum_of_assigned_layers+num_layers); layer_id++){" + "\n"
    line += "        printf(\"\\t%d\\n\", layer_id);" + "\n"
    line += "        for(int tf_count=0; tf_count<layerWiseTFBufDepth[layer_id]/2; tf_count++){" + "\n"
    line += "          for(int v_seg_id=0; v_seg_id<TF_LOAD_V_SEGS_PER_PARA_LIMB; v_seg_id++){" + "\n"
    line += "            " + "\n"
    line += "            int tf_port_id = h_seg_id * TF_LOAD_V_SEGS_PER_PARA_LIMB + v_seg_id;" + "\n"
    line += "" + "\n"
    line += "            TF_WIDE_DATA_PER_PARA_LIMB val = 0;" + "\n"
    line += "" + "\n"
    line += "            for(int comb_id=TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2-1; comb_id>=0; comb_id--){" + "\n"
    line += "              val = val << (DRAM_WORD_SIZE*2);" + "\n"
    line += "              int buf_id = v_seg_id*(TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2)+comb_id;" + "\n"
    line += "              WORD smallVal_0 = layerWiseTFBuf[layer_id][buf_id][2*tf_count];" + "\n"
    line += "              WORD smallVal_1 = layerWiseTFBuf[layer_id][buf_id][2*tf_count+1];" + "\n"
    line += "              val = val | ( ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_1 ) << WORD_SIZE ) | ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_0 );" + "\n"
    line += "            }" + "\n"
    line += "            outVec[tf_port_id].push_back(val);" + "\n"
    line += "          }" + "\n"
    line += "        }" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "    else{" + "\n"
    line += "      for(int layer_id=(cummulative_sum_of_assigned_layers+num_layers-1); layer_id>=(cummulative_sum_of_assigned_layers); layer_id--){" + "\n"
    line += "        printf(\"\\t%d\\n\", layer_id);" + "\n"
    line += "        for(int tf_count=0; tf_count<layerWiseTFBufDepth[layer_id]/2; tf_count++){ //two values packed together" + "\n"
    line += "          for(int v_seg_id=0; v_seg_id<TF_LOAD_V_SEGS_PER_PARA_LIMB; v_seg_id++){" + "\n"
    line += "            " + "\n"
    line += "            int tf_port_id = h_seg_id * TF_LOAD_V_SEGS_PER_PARA_LIMB + v_seg_id;" + "\n"
    line += "" + "\n"
    line += "            TF_WIDE_DATA_PER_PARA_LIMB val = 0;" + "\n"
    line += "" + "\n"
    line += "            for(int comb_id=TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2-1; comb_id>=0; comb_id--){" + "\n"
    line += "              val = val << (DRAM_WORD_SIZE*2);" + "\n"
    line += "              int buf_id = v_seg_id*(TF_CONCAT_FACTOR_PER_PARA_LIMB_PORT/2)+comb_id;" + "\n"
    line += "              WORD smallVal_0 = layerWiseTFBuf[layer_id][buf_id][2*tf_count];" + "\n"
    line += "              WORD smallVal_1 = layerWiseTFBuf[layer_id][buf_id][2*tf_count+1];" + "\n"
    line += "              val = val | ( ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_1 ) << WORD_SIZE ) | ( (TF_WIDE_DATA_PER_PARA_LIMB)smallVal_0 );" + "\n"
    line += "            }" + "\n"
    line += "            outVec[tf_port_id].push_back(val);" + "\n"
    line += "          }" + "\n"
    line += "        }" + "\n"
    line += "      }" + "\n"
    line += "    }" + "\n"
    line += "    cummulative_sum_of_assigned_layers+=num_layers;" + "\n"
    line += "  }" + "\n"
    line += "}" + "\n"
    
    return line

# A wrapper function which include both FWD and INV tf coversion to DRAM ports
def gen_reorganize_input_tfs_to_ports():

    line  = ""
    
    line += "void reorganize_input_tfs_to_ports(std::vector<WORD> (&inVec)[PARA_LIMBS], std::vector<TF_WIDE_DATA, tapa::aligned_allocator<TF_WIDE_DATA>> (&outVec)[TF_PORTS], bool direction){" + "\n"
    line += "  " + "\n"
    line += "  std::vector<TF_WIDE_DATA_PER_PARA_LIMB, tapa::aligned_allocator<TF_WIDE_DATA_PER_PARA_LIMB>> limbWiseInTFData[PARA_LIMBS][TF_PORTS_PER_PARA_LIMB];" + "\n"
    line += "  " + "\n"
    line += "  for(VAR_TYPE_32 paraLimbCounter=0; paraLimbCounter<PARA_LIMBS; paraLimbCounter++){" + "\n"
    line += "    if(direction){" + "\n"
    line += "      fwd_organizeTFData(inVec[paraLimbCounter], limbWiseInTFData[paraLimbCounter]);" + "\n"
    line += "    }" + "\n"
    line += "    else{" + "\n"
    line += "      inv_organizeTFData(inVec[paraLimbCounter], limbWiseInTFData[paraLimbCounter]);" + "\n"
    line += "    }" + "\n"
    line += "  }" + "\n"
    line += "" + "\n"
    line += "  reorganize_para_limbs_to_ports_tf(limbWiseInTFData, outVec);" + "\n"
    line += "}" + "\n"
    
    return line

def gen_TF_data_rearrange_functions(designParamsVar):
    line = ""

    # TF generation function
    line += gen_genTF_function()
    line += "\n"

    # Parallel limbs to DRAM port conversion
    line += gen_reorganize_para_limbs_to_ports_tf()
    line += "\n"

    # FWD TF rearrange
    line += gen_fwd_TF_data_rearrange(designParamsVar)
    line += "\n"

    # INV TF rearrange
    line += gen_inv_TF_data_rearrange(designParamsVar)
    line += "\n"

    # TF array to DRAM ports
    line += gen_reorganize_input_tfs_to_ports()
    line += "\n"

    return line